{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the numbers in the file have commas for thousands set the argument thousands = , \n",
    "df = pd.read_csv('...csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data audit\n",
    "\n",
    "#turn ? to nan values\n",
    "audit = df.replace('?', np.nan)\n",
    "\n",
    "#copy data audit to clipboard - this shows how many nan values in each column (paste this to excel)\n",
    "audit.isnull().sum().to_clipboard()\n",
    "\n",
    "#shows overall info (opposite, shows how many non-null values)\n",
    "audit.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# value count\n",
    "pd.value_counts(df.MBRSHP_LVL_CD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick selected columns (  remember to use two [[   ]]   )\n",
    "\n",
    "df = df[['example1', 'example2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check to see data types \n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace values \n",
    "df[[ 'example1' ]] = df[[ 'example1' ]].replace('?', 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change data type for a column\n",
    "\n",
    "df[[ 'example1' ]] = df[[ 'example1' ]].astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace values to NAN \n",
    "#therefore we can drop Nan values\n",
    "\n",
    "\n",
    "df[[ 'example1' ]] = df[[ 'example1' ]].replace(11, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#useful to see how many columns before dropping NAN values\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop NAN values for every column \n",
    "#check to see how many has been lost   ---   If too many values have been lost, check data and possilble restart kernel\n",
    "\n",
    "df_BASE_2018 = df_BASE_2018.dropna()\n",
    "df_BASE_2018.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sometimes date formats need to be changed to datetime64[ns]  \n",
    "# this is so you can use functions such as find the month or subract dates to find days \n",
    "\n",
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"], dayfirst=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example below is creating your own functon and applying it for every row of that column\n",
    "\n",
    "def weekday(x):\n",
    "    return x.weekday()\n",
    "\n",
    "#function above finds what day of the week the date value is\n",
    "#applying the weekday function to the column Date and creating a new column called weekend\n",
    "\n",
    "df['Weekend'] = df['Date'].apply(weekday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_BASE_2018.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the below method is a more complex apply function. \n",
    "#this is normally used when two columns are being used in a function. \n",
    "#Example_function is being applied of which involves example1 and example2 columns.\n",
    "#becasue the function being applied to both example1 and example2 it is stated df[['example1','example2']] before the apply\n",
    "#A new column called NewColumn is being created.\n",
    "\n",
    "df['NewColumn'] = df[['example1','example2']].apply(lambda row: Example_FUNCTION(row['example1'], \n",
    "                                                                                  row['example2']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if any NAN values from the function\n",
    "df[df.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check how many unique example1 values\n",
    "df[['example1']].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check how many unique values of two columns\n",
    "#example see if there is an example1 value for each month of the year\n",
    "#You should know if there is missing data from using the value previously above. e.g. value above *12\n",
    "df.groupby(['example1', 'Month']).ngroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#example of filtering\n",
    "df = df[df['Country'] == \"UNITED KINGDOM\"]\n",
    "\n",
    "#multiple \n",
    "df[(df[Gender]=='Male') & (df[Year]==2014)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#example of renaming columns\n",
    "df.rename(columns={'example1': 'Example_1'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change all column names\n",
    "df = df.rename(columns=lambda x: x.replace('NBR', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change all individually\n",
    "df.columns = [['Month', '2018_GuestLove','2017_GuestLove', '2017 Diff']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merging columns\n",
    "#merge two files on a value \n",
    "#column names need to be the same\n",
    "#column datatypes need to be the same \n",
    "#inner means no null values - different types are inner, outer, left and right\n",
    "\n",
    "df = pd.merge(df, df1, on=['Example_1'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping columns \n",
    "df = df.drop(['example2'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save dataframe to csv file (error will occur if already done this and have the file open)\n",
    "df.to_csv('NameOfFile.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count how many different classification categories there are in the column 'Category'\n",
    "pd.value_counts(df6['Category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pivot tables \n",
    "\n",
    "table1 = pd.pivot_table(df1, index = ['Property Identifier', 'Month'], \n",
    "                       values = ['Rival STR Name'], aggfunc ={'Rival STR Name':rival_brands})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_by = df.groupby(['FAC_ID', 'MO_NBR']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_values_table(df):\n",
    "        # Total missing values\n",
    "        mis_val = df.isnull().sum()\n",
    "        \n",
    "        # Percentage of missing values\n",
    "        mis_val_percent = 100 * df.isnull().sum() / len(df)\n",
    "        \n",
    "        # Make a table with the results\n",
    "        mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n",
    "        \n",
    "        # Rename the columns\n",
    "        mis_val_table_ren_columns = mis_val_table.rename(\n",
    "        columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n",
    "        \n",
    "        # Sort the table by percentage of missing descending\n",
    "        mis_val_table_ren_columns = mis_val_table_ren_columns[\n",
    "            mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n",
    "        '% of Total Values', ascending=False).round(1)\n",
    "        \n",
    "        # Print some summary information\n",
    "        print (\"Your selected dataframe has \" + str(df.shape[1]) + \" columns.\\n\"      \n",
    "            \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n",
    "              \" columns that have missing values.\")\n",
    "        \n",
    "        # Return the dataframe with missing information\n",
    "        return mis_val_table_ren_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get the columns with > 50% missing\n",
    "missing_df = missing_values_table(data);\n",
    "missing_columns = list(missing_df[missing_df['% of Total Values'] > 50].index)\n",
    "print('We will remove %d columns.' % len(missing_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns = list(missing_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slice columns from middle to last  (include all rows by indicating ':' at the start)\n",
    "df1 = df.loc[:, 'Middle column':'Last Column']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check to see if any values are below 12\n",
    "df1 = df1[(df1 <= 12).any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for null data\n",
    "df[pd.isnull(df).any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to list only the same hotels in df1 and df2\n",
    "hotel_list = df.groupby(['Hotel Code']).sum()\n",
    "hotel_list = hotel_list.reset_index()\n",
    "hotel_list = hotel_list['Hotel Code']\n",
    "hotel_list = list(str(e) for e in hotel_list)\n",
    "df2 = df2.loc[df2['Hotel Code'].isin(hotel_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hotel Code    280\n",
      "Month          12\n",
      "dtype: int64\n",
      "Number of unique entries is: 3360\n"
     ]
    }
   ],
   "source": [
    "print(df[['Hotel Code', 'Month']].nunique())\n",
    "print('Number of unique entries is:', df.groupby(['Hotel Code', 'Month']).ngroups)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
